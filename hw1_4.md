- Without prefetching, the time required to fetch two cache lines is twice the latency (100ns) plus twice the pure data transfer (bandwidth) contribution (10 ns), which adds up to 220 ns. Since a cache line holds four entries, eight flops (two multiplications and two additions per entry) can be performed on this data. Thus, the expected performance is 8 Flops/220 ns = 36 MFlops/sec.
- According to Eq.(1.6), 1+100/10=11outstanding prefetches are required to hide latency. Note that this result does not depend on the number of concurrent streams only if we may assume that achievable bandwidth is independent of this number.
- If the length of the cache line is increased, latency stays unchanged but it takes longer to transfer the data, i.e., the bandwidth contribution to total transfer time gets larger. With a 64-byte cache line, we need 1 + 100/20 = 6 outstanding prefetches, and merely 1 + 100/40 ≈ 4 at 128 bytes.
- Transferring two cache lines without latency takes 20 ns, and eight Flops can be performed during that time. This results in a theoretical performance of 4×108 Flops/sec, or 400 MFlops/sec.
